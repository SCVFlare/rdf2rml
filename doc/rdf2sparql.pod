=head1 NAME

rdf2sparql - Convert RDF examples to SPARQL queries (Ontotext Refine or TARQL)

=head1 SYNOPSIS

  perl rdf2sparql.pl             model.ttl | cat common.h prefixes.rq - | cpp -P -C -nostdinc - > model-ontorefine.ru
  perl rdf2sparql.pl --construct model.ttl | cat common.h prefixes.rq - | cpp -P -C -nostdinc - > model-ontorefine.rq
  perl rdf2sparql.pl --tarql     model.ttl | cat common.h prefixes.rq - | cpp -P -C -nostdinc - > model.tarql

  Options:
    --construct: generate CONSTRUCT query (default is UPDATE; applies only for Ontotext Refine)
    --tarql: generate for TARQL (default is Ontotext Refine)

=head1 DESCRIPTION

B<rdf2sparql> converts an RDF example with embedded CSV/TSV column names into a SPARQL query for:

=over

=item * L<TARQL|https://tarql.github.io/>, which is a is a high-speed streaming convertor. It's a SPARQL processor for tabular data, where each column B<col> of each row is exposed as a variable binding B<?col> (punctuation is replaced with underscores). See L<releases|https://github.com/tarql/tarql/releases>, tested with version 1.2-SNAPSHOT, BUILD_DATE: 2017-12-07T13:33:10Z


=item * L<Ontotext Refine|https://graphdb.ontotext.com/documentation/standard/loading-data-using-ontorefine.html>, which is an adaptation of OpenRefine for working with RDF data. It exposes a table as a virtual SPARQL endpoint (special service), where each column B<col> of each row is exposed as a variable binding B<?c_col>.

=back

We've used TARQL to convert large files (over 10M rows, 145 columns) using complex TARQL queries (480 lines: 110 prefixes, 33 nodes, 250 triples, 110 binds).

We've used Ontotext Refine for large and complex CSV files,
e.g. CrunchBase consisting of 18 tables, total 10.5M rows, 318 columns;
for both initial loading and data updates.
See L<CrunchBase Challenge|https://gist.github.com/VladimirAlexiev/d5d67feb002dbcfa6b3d4c3dd59b52da> for details.
(Please note that we use a customized script that works with named graph per B<table row>, not per B<table>.)

=head2 Options

The default is to generate a SPARQL UPDATE query for Ontotext Refine.
It encloses Ontotext Refine variables in a B<service> clause that accesses the Ontotext Refine virtual SPARQL endpoint
(see later about the handling of B<PROJECT_ID>):

  service <rdf-mapper:ontorefine:PROJECT_ID> {
    ...
  }

This has several benefits:

=over

=item * It ingests directly to GraphDB (without producing an intermediate RDF file), which is faster.

=item * It overwrites a named graph, so it can be used for ingest or update. The first model line must look like this where B<graph> is the graph to overwrite (in angle brackets). You can use parenthesized variable name(s) to compute the graph at runtime (see second example from Crunchbase):

  # GRAPH <constant_graph>
  # GRAPH <graph/organizations/(uuid)>

=item * You can match real triples in GraphDB, which can be used to resolve entities ("strings" to "things"). A macro name that ends in "URL" (case-insensitively), e.g. B<CB_AGENT_URL(permalink)>, causes the respective patterns to be interpreted outside of the Ontotext Refine virtual service.

=item * You can split several multi-valued columns (using the B<SPLIT> macro) to produce multiple bindings, without fear of Cartesian Product (i.e. their values will not be combined with each other).

=back

Option B<-construct> generates a SPARQL CONSTRUCT query.
You can still match GraphDB triples and use multiple multi-valued columns.
Any B<GRAPH> comment is ignored, because CONSTRUCT does not support graphs
(see L<SPARQL 1.2 issue 31|https://github.com/w3c/sparql-12/issues/31>).
The query produces intermediate RDF data that must be saved before loading to GraphDB,
then you can use the L<SPARQL Graph Store Protocol|https://www.w3.org/TR/sparql11-http-rdf-update/>
to overwrite the respective graph.

Option B<--tarql> generates a TARQL CONSTRUCT query.
You should put each multivalued column (together with the primary key column)
in a distinct model to avoid Cartesian Product.
You cannot
match RDF data in a repository (see L<TARQL issue 25|https://github.com/tarql/tarql/issues/25>),
use UPDATE (see L<TARQL issue 67|https://github.com/tarql/tarql/issues/67>),
nor use graphs (see L<TARQL issue 98|https://github.com/tarql/tarql/issues/98>).

You can abbreviate options. All these are equivalent:

  --c --co --construct
  --t --ta --tarql

=head2 Prerequisites

=over

=item * Ontotext Refine or TARQL as described above

=item * Perl. Tested with 5.32.1 (Straberry Perl on Cygwin)

=item * Working CPP preprocessor. Tested with 8.3.0 (x86_64-posix-seh, Built by strawberryperl.com project)

=item * A file (eg B<prefixes.rq>) that defines all common prefixes and is prepended to the generated query

=item * A file (eg B<common.h>) that defines CPP preprocessor macros

=back

=head2 Process

=over

=item * Make a B<rdfpuml> semantic model for a single table, using field names as parenthesized embeds. See below for several examples.

=item * Run the script followed by the CPP proprocessor as shown above and save the SPARQL script

=back

To process CSV/TSV with the generated SPARQL scripts, use the following steps.

Process with B<model.tarql> (variants for CSV or TSV):

  tarql    model.tarql data.csv > data.ttl
  tarql -t model.tarql data.tsv > data.ttl

Process B<model-ontorefine.ru> with Ontotext Refine:

=over

=item * Create a project, load tabular data

=item * Optionally, perform data cleaning

=item * Make sure you have a working GraphDB repository to receive the data

=item * Paste the generated SPARQL into GraphDB workbench and adjust B<PROJECT_ID> to the actual Refine virtual endpoint and project ID

=item * Run the query to update the data in GraphDB

=back

If you save the Ontotext Refine cleaning script (operations JSON),
you can automate the Ontotext Refine process by using the
L<ontorefine-client|https://github.com/Ontotext-AD/ontorefine-client> CLI
(it will become part of the Ontotext Refine distribution).
We have scripts to automate the following steps:

=over

=item * Create an Ontotext Refine project and capture its project ID

=item * Load tabular data into the Ontotext Refine project

=item * Optionally, apply an OpenRefine data cleaning script

=item * Replace the placeholder B<PROJECT_ID> in the generated query with the actual ID

=item * Run the query against a GraphDB repository: it will replace the defined named graph

=item * Delete the Ontotext Refine project

=back

=head2 RDF Model Examples

B<rdfpuml> models are RDF Turtle examples that use parenthesized column names
in URLs ("templated URLs") and in attribute values (which can be datatyped).

They are valid Turtle, with the exception that RDF tools issue warnings
about templated literals such as B<"(some_date)"^^xsd:date> or B<"(amount)"^^xsd:decimal>.

You can also use "functions" that you need to implement as CPP macros.
B<rdf2sparql> takes care to unroll the functions into BINDs, adding suffixes to variable names.

See also B<test/customer> for a separate example (includes a Makefile).

=head3 RDF Model: CrunchBase Organizations

The first example is a simple semantic representation of CrunchBase's B<organizations.csv> table:

  # GRAPH <graph/organizations/(uuid)>
  
  <cb/agent/(uuid)> a cb:Organization;
    cb:uuid '(uuid)';
    cb:name '(name)';
    cb:permalink '(permalink)';
    cb:url '(cb_url)'^^xsd:anyURI;
    cb:rank '(rank)'^^xsd:integer;
    cb:createdAt 'FIXDATE(created_at)'^^xsd:dateTime;
    cb:updatedAt 'FIXDATE(updated_at)'^^xsd:dateTime;
    cb:legalName '(legal_name)';
    cb:organizationRole <cb/organizationRole/URLIFY(SPLIT_COMMA(roles))>;
    cb:domain '(domain)';
    cb:homepageUrl '(homepage_url)'^^xsd:anyURI;
    cb:countryCode '(country_code)';
    cb:stateCode '(state_code)';
    cb:region '(region)';
    cb:city '(city)';
    cb:address '(address)';
    cb:postalCode '(postal_code)';
    cb:status <cb/organizationStatus/URLIFY(status)>;
    cb:shortDescription '(short_description)';
    cb:industry <cb/industry/URLIFY(SPLIT_COMMA(category_list))>;
    cb:numFundingRounds '(num_funding_rounds)'^^xsd:integer;
    cb:totalFundingUsd '(total_funding_usd)'^^xsd:decimal;
    cb:totalFunding '(total_funding)'^^xsd:decimal;
    cb:totalFundingCurrencyCode '(total_funding_currency_code)';
    cb:foundedOn 'FIXDATE(founded_on)'^^xsd:dateTime;
    cb:lastFundingOn 'FIXDATE(last_funding_on)'^^xsd:dateTime;
    cb:closedOn 'FIXDATE(closed_on)'^^xsd:dateTime;
    cb:employeeCount <cb/employeeCount/URLIFY(IFNOTNULL(employee_count))>;
    cb:email '(email)';
    cb:phone '(phone)';
    cb:facebookUrl '(facebook_url)'^^xsd:anyURI;
    cb:linkedinUrl '(linkedin_url)'^^xsd:anyURI;
    cb:twitterUrl '(twitter_url)'^^xsd:anyURI;
    cb:logoUrl '(logo_url)'^^xsd:anyURI;
    cb:alias '(alias1)';
    cb:alias '(alias2)';
    cb:alias '(alias3)';
    cb:primaryRole <cb/organizationRole/URLIFY(primary_role)>;
    cb:numExits '(num_exits)'^^xsd:integer.

It puts all fields in one table and uses macros like
URLIFY to make a phrase usable in URL,
IFNOTNULL to discard parasitic phrases,
SPLIT to split a multi-valued field into multiple bindings, etc.
It uses a GRAPH comment to specify which named graph should be overwritten: it is computed dynamically from the "uuid" field.

=head3 RDF Model: Customers

Next is an example about persons (customers).

    <person/(customer_id)> a :NaturalPerson;
      :id "(customer_id)";
      :firstName "(first_name)";
      :lastName "(last_name)";
      :gender "(gender)";
      :religion "(religion)";
      :hasAddress <person/(customer_id)/address>;
      :hasEvent  <person/(customer_id)/birth>;
      :hasEvent  <person/(customer_id)/education>.

    <person/(customer_id)/address> a :Address;
      :houseNumber "(house_number)";
      :street "(street)";
      :postalCode "(postal_code)";
      :city <country/(country)/city/URLIFY(city)>;
      :country <country/(country)>.

    <country/(country)/city/URLIFY(city)> a :City; :country <country/(country)>; :name "(city)".

    <country/(country)> a :Country; :code "(country)".

    <person/(customer_id)/birth> a :BirthEvent; :hasDate "(date_of_birth)"^^xsd:date.

    <person/(customer_id)/education> a :EducationEvent;
      :hasDate "(enrollment_date)"^^xsd:date;
      :university <university/URLIFY(university)>;
      :degree <degree/URLIFY(education_degree)>.

It dispatches fields to several nodes and uses only one macro (B<URLIFY>).

=head3 RDF Model: Annual Revenue by Permalink

Next is a very simple model that adds a field "revenue" to CrunchBase organizations,
based on two columns: "permalink" identifying the company, and "revenue" being a decimal

  # GRAPH <extra/(permalink)/revenue>
  <CB_AGENT_URL(permalink)> ex:annualRevenueUsd "(revenue)"^^xsd:decimal.

The revenue is keyed by "permalink".
But CrunchBase organizations use a different URL (primary key) based on "uuid".
So we use the B<CB_AGENT_URL()> macro to lookup by permalink.

=head3 RDF Model: Grant Spending Categories

This model of NIH grants assumes that an application (with primary key B<APPLICATION_ID>)
can have multiple spending categories (field B<NIH_SPENDING_CATS>) separated by semi-colon.
To avoid Cartesian Product with TARQL, we put this one field in a separate model file:

  <grant/(APPLICATION_ID)> gr:spendingCategory <spendingCategory/URLIFY(SPLIT_SEMI(NIH_SPENDING_CATS))>.

  <spendingCategory/URLIFY(SPLIT_SEMI(NIH_SPENDING_CATS))>
    a skos:Concept ;
    skos:inScheme  <spendingCategory> ;
    skos:prefLabel "SPLIT_SEMI(NIH_SPENDING_CATS)".

  <spendingCategory>
    a skos:ConceptScheme ;
    skos:prefLabel  "NIH spending category".

Note that in addition to making the B<gr:spendingCategory> relation, this model also emits extra nodes.
This will lead to redundant triples:
each individual B<skos:Concept> is duplicated as many times as it's used in grants,
and B<skos:ConceptScheme> is duplicated as the total number of grants.

This does not lead to conflicts since the same triple cannot be recorded multiple times in an RDF repository.
However, if this data redundancy is bothersome, you can
normalize the Concept data to a separate file of unique concepts;
and move the ConceptScheme into a separate "constant" RDF file
that doesn't need to be processed with B<rdf2sparql>.

=head3 Filtering

You can use the field B<puml:label> to specify a filter condition to be applied for each row.
For example, let's say we have a table of some content (web pages)
that needs to be published as RDF only when the field B<status> is "published".
Use the following model:

  <(url)> a s:WebPage;
    puml:label "filter(?status='published')"; ## RDFize only "published" pages
    s:name     "(title)";
    s:author   "(author)";
    s:date     "(date)"^^xsd:date.

B<puml:label> is printed out in red, and its contents are added at the end of the query.
For Ontotext Refine, this will look like:

  delete ...
  insert ...
  where {
    service <rdf-mapper:ontorefine:PROJECT_ID> {
      ...
      filter(?status='published')
    }
  }

For TARQL, this will look like:

  construct ...
  where {
    ...
    filter(?status='published')
  }

See the folder B<filter-content> for a complete test case using TARQL.
There are 3 rows in B<content.csv> but the first one doesn't have B<status='published'>,
so it's omitted from B<content-result.ttl>.

Notes:

=over

=item * Don't forget to write out B<filter(...)> and use question marks to identify the variables (fields).

=item * Since the model Turtle is not really parsed, you should write the B<puml:label> on one line, trailed by semicolon or dot (and optional trailing comment).

=item * You can use triple quotes or apostrophes to surround the content.

=item * The same field is used in B<rdf2rml> with a completely different meaning: as a SQL table or query. I know, this is an ugly hack.

=back

=head3 Conditional Nodes

Consider the following more advanced model, which maps Crunchbase data to the
L<euBusinessGraph model|https://github.com/euBusinessGraph/eubg-data/tree/master/model>
(see L<google doc|https://docs.google.com/document/d/1dhMOTlIOC6dOK_jksJRX0CB-GIRoiYY6fWtCnZArUhU/edit>),
which itself uses W3C Org, ADMS, Schema.org, etc.

=for html
<img src="../test/conditional-node/organizations.png">

See the test L<conditional-node|../test/conditional-node>,
in particular the model is L<organizations.ttl|../test/conditional-node/organizations.ttl>
and the key parts look like this:

   <cb/agent/(uuid)> a org:Organization;
     org:hasSite <cb/agent/(uuid)/_IF_BOUND(address,country_code,region,postal_code,street)>;
     adms:identifier
       <cb/agent/(uuid)/id/_IF_BOUND(facebook,facebookUrl)>,
       <cb/agent/(uuid)/id/_IF_BOUND(linkedin,linkedinUrl)> .
   <cb/agent/(uuid)/_IF_BOUND(address,country_code,region,postal_code,street)> a locn:Address;
     ...
   <cb/agent/(uuid)/id/_IF_BOUND(facebook,facebookUrl)> a adms:Identifier;
     ...
   <cb/agent/(uuid)/id/_IF_BOUND(linkedin,linkedinUrl)> a adms:Identifier;

We emit some of the fields in structured nodes.
But we want to create these nodes only if the fields are bound,
i.e. we don't want to create parasitic "empty" nodes with no business payload.
For this we create the B<_IF_BOUND(...)> macro, see L<common.h|../test/conditional-node/common.h>.
It uses techniques from this L<StackOverflow answer|https://stackoverflow.com/a/65997567/20282178>
about iteration over C<__VA_ARGS_> variadic extra arguments (in this case, limited to 5).

  #define __IF_BOUND_1(x,y1)             bind(if(bound(?y1),#x,?UNDEF) as ?x##_IF_BOUND)
  #define __IF_BOUND_2(x,y1,y2)          bind(if(bound(?y1)||bound(?y2),#x,?UNDEF) as ?x##_IF_BOUND)
  #define __IF_BOUND_3(x,y1,y2,y3)       bind(if(bound(?y1)||bound(?y2)||bound(?y3),#x,?UNDEF) as ?x##_IF_BOUND)
  #define __IF_BOUND_4(x,y1,y2,y3,y4)    bind(if(bound(?y1)||bound(?y2)||bound(?y3)||bound(?y4),#x,?UNDEF) as ?x##_IF_BOUND)
  #define __IF_BOUND_5(x,y1,y2,y3,y4,y5) bind(if(bound(?y1)||bound(?y2)||bound(?y3)||bound(?y4)||bound(?y5),#x,?UNDEF) as ?x##_IF_BOUND)

  #define __IF_BOUND_PICK_N(_1,_2,_3,_4,_5,N,...) __IF_BOUND_##N
  #define _IF_BOUND(x,...) __IF_BOUND_PICK_N(__VA_ARGS__,5,4,3,2,1)(x,__VA_ARGS__)

Several things are going on here:

=over

=item * First we define 5 macros that handle the cases of 1..5 extra arguments.

=item * They use a disjunction of B<bound()> to check if any of the extra arguments are bound. 

=item * If so, the "stringify" macro operator B<#> returns the "string representation" of the first argument.

=item * Otherwise, the B<?UNDEF> variable is returned, which by convention is never bound.

=item * Be careful about the output variable: we need to write out the question mark before it (since the same name B<x> is also used in its stringified form), and we follow it by one underscore B<_> even though the macro name itself starts with underscore.

=item * The macro B<__IF_BOUND_PICK_N> uses the B<##> token concatenation operator to pick one of the 5 macros. 

=item * The final macro B<_IF_BOUND> calls B<__IF_BOUND_PICK_N> with a carefully crafted tail sequence B<5,4,3,2,1>. Eg if B<__VA_ARGS__> has 4 elements, they will be eaten up by the argumentss B<_1,_2,_3,_4>. The constant B<5> will be eaten by the argument B<_5>, so the argument B<N> will be bound to the next constant B<4>, so the macro B<__IF_BOUND_4> will be picked.

=item * After the correct macro is picked, all arguments B<(x,__VA_ARGS__)> are passed to it. So you see that in the implementation of B<_IF_BOUND>, B<__VA_ARGS__> is used twice: first to pick the correct numbered macro, then to provide it with arguments.

=back

When B<rdf2sparql> sees a macro name starting with underscore B<_>, it leaves its arguments alone (doesn't add a question mark before the first argument), and doesn't prepend an extra underscore before the macro name.

This results in the following binds in the B<where> clause:

    bind(if(bound(?country_code)||bound(?region)||bound(?postal_code)||bound(?street),"address",?UNDEF) as ?address_IF_BOUND)
    bind(iri(concat("cb/agent/",?uuid,"/",?address_IF_BOUND)) as ?cb_agent_uuid_address_IF_BOUND_URL)
    bind(if(bound(?facebookUrl),"facebook",?UNDEF) as ?facebook_IF_BOUND)
    bind(iri(concat("cb/agent/",?uuid,"/id/",?facebook_IF_BOUND)) as ?cb_agent_uuid_id_facebook_IF_BOUND_URL)
    bind(if(bound(?linkedinUrl),"linkedin",?UNDEF) as ?linkedin_IF_BOUND)
    bind(iri(concat("cb/agent/",?uuid,"/id/",?linkedin_IF_BOUND)) as ?cb_agent_uuid_id_linkedin_IF_BOUND_URL)

To explain the first two lines:
first we check if any of the "business payload" fields are bound, and return the string "address" or UNDEF.
Then we concat this string with some constant and variabel parts to form a URL.
If the string is unbound, then the URL will be unbound.
Then any triple using the unbound URL will B<not> be emitted, avoiding the creation of a parasitic node.

=head3 RDF Model Concatenation

B<rdf2sparql> works on a single CSV table at a time (B<rdf2rml> does not have this limitation).
Furthermore, as seen above, you may need to split a model
into "component" sub-models to handle multi-valued columns.
Making diagrams from such tiny models is not very useful.

Luckily, concatenating several Turtle files is also a valid Turtle.
So you can make an overall model by concatenating the component models.

Here is a Makefile from a recent project.
It specifies how to make the overall B<nih-model.ttl>, and then the diagram B<nih-model.png> from it.

  all: nih-model.ttl nih-model.png prefixes.rq

  nih-model.ttl: prefixes.ttl nih-activityType.ttl nih-applicationType.ttl nih-department.ttl \
    nih-funder.ttl nih-funding.ttl nih-fundingMechanism.ttl nih-grant.ttl nih-linkClinicalStudy.ttl \
    nih-linkPatent.ttl nih-linkPublication.ttl nih-principalInvestigator.ttl nih-researcher.ttl \
    nih-spendingCategory.ttl nih-studySection.ttl puml.ttl
          cat $^ | perl nih-model-rename.pl > $@

  %.png: %.ttl
          rdfpuml.bat $*.ttl
          puml.bat $*.puml
          rm $*.puml

  prefixes.rq: prefixes.ttl
          perl -pe 'm{###} and last; s{^@}{}; s{ *\.$$}{}' $^ > $@

It uses a shared B<prefixes.ttl> and its SPARQL variant B<prefixes.rq>
that is prepended to any generated query.
To ensure connectivity of the overall model, a script like B<nih-model-rename.pl> renames
URLs in object position ("foreign keys")
to respective URLs in subject position ("primary keys"), e.g.:

  #!perl -p

  s{\Q/FIND_CONTACT(PI_IDS)}{/(PI_ID)};
  s{\Q/OMIT_CONTACT(PI_IDS)}{/(PI_ID)};
  s{\Q/FUNDER(FUNDING_ICs)}{/(FUNDING_IC)};


=head2 Preprocessor Macros

In addition to plain CSV field names you can also use macros ("function calls")
that are unrolled by the script into a series of binds using suffixed variable names.
Below are some examples we've used in various projects.
These are implemented as CPP preprocessor macro definitions (e.g. in file B<common.h>):

=over

=item * make a name usable in URL. Replace punctuations with one underscore; remove leading/trailing punctuation. Support all Unicode alphanumeric chars. Convert alphabetical to lowercase.

  #define URLIFY1(x)      lcase(replace(replace(replace(x, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", ""))

=item * same but also generates a bind to x_URLIFY

  #define URLIFY(x)       bind(URLIFY1(x) as x##_URLIFY)

=item * replace space with "T" in a timestamp to conform to xsd:dateTime format

  #define FIXDATETIME(x)  bind(replace(x,' ','T') as x##_FIXDATETIME)

=item * convert dates from mm/dd/yyyy to yyyy-mm-dd to conform to xsd:date forma

  #define FIXDATE(x)      bind(replace(x,"(..)/(..)/(....)","$3-$1-$2") as x##_FIXDATE)

=item * lookup a CrunchBase permalink to find the respective agent (organization or person) URL

  #define CB_AGENT_URL(x) filter(bound(x)) x##_CB_AGENT_URL a x##_TYPE; k2:permalink x filter(x##_TYPE in (cb:Person,cb:Organization))

=item * filter out parasitic values ("other","not provided","unknown")

  #define IFNOTNULL(x)    bind(if(x in ("other","not provided","unknown"),?UNDEF,x) as x##_IFNOTNULL)

=item * filter out x values that are equal to ?y. Used to strip self-referential parent: CB category mentioning itself as category_group

  #define IFNOTSAME(x,y)  bind(if(x=y,?UNDEF,x) as x##_IFNOTSAME)

=item * assign the first bound variable amongst the B<...> arguments to variable B<x##_COALESCE>

  #define COALESCE(x,...) bind(coalesce(__VA_ARGS__) as x##_COALESCE)

=item * map "Yes","No" to "true","false" respectively

  #define YESNO(x)        bind(if(x="Yes",true,false) as x##_YESNO)

=item * split B<x> on a given delimiter B<y> and produce multiple bindings in variable B<z>

  #define SPLIT(x,y,z)    z apf:strSplit (x y).

=item * split on semicolon (optionally followed by space) and produce multiple bindings.

  #define SPLIT_SEMI(x)   SPLIT(x,"; ?",x##_SPLIT_SEMI)

=item * split on comma (optionally followed by space) and produce multiple bindings.

  #define SPLIT_COMMA(x)  SPLIT(x,", ?",x##_SPLIT_COMMA)

=item * find a numeric identifier element marked as " (contact)"

  #define FIND_CONTACT(x) bind(replace(x, ".*?([0-9]+) \\(contact\\).*", "$1") as x##_FIND_CONTACT)

=item * split on semicolon and return all numeric identifiers except the one marked as " (contact)"

  #define OMIT_CONTACT(x) SPLIT_SEMI(x)  bind(if(regex(x##_SPLIT_SEMI,"^$| \\(contact\\)",?UNDEF,x##_SPLIT_SEMI) as x##_OMIT_CONTACT)

=item * split on backslash then return the first B<:>-delimited part of each pair (funder code)

  #define FUNDER(x)       SPLIT(x,"\\\\",x##_SPLIT_BACKSL) bind(replace(x##_SPLIT_BACKSL,"(.+):(.+)","$1") as x##_FUNDER)

=item * return the second B<:>-delimited part of each pair (amount). Must be used together with B<FUNDER(x)> because it uses B<x##_SPLIT_BACKSL> without binding it

  #define AMOUNT(x)                                        bind(replace(x##_SPLIT_BACKSL,"(.+):(.+)","$2") as x##_AMOUNT)

=item * bind variable B<?x_IF_BOUND> to the string "x" if any of the extra arguments is bound, else leave it unbound

  #define _IF_BOUND(x,...)  // see definition in section Conditional Nodes

=back

Most of the macros implement binds (computations), but you can also use more specialized constructs.
Notes about unusual constructs:

=over

=item * B<URLIFY1(x)> uses the Unicode character class B<\p{L}> for "Letters"

=item * B<IFNOTNULL(x)> and B<IFNOTSAME(x)> use a conditional and the variable B<?UNDEF>, which by convention is never bound, so is undefined

=item * B<##> concatenates two preprocessor tokens (a variable name and a constant string) to make a new variable name

=item * B<CB_AGENT_URL(x)>: uses a real RDF lookup (outside of the Ontotext Refine virtual endpoint). Before that guards with B<bound(x)> (otherwise an unbound variable will return all agents), then checks for respective B<rdf:type>

=item * B<SPLIT(x)>: uses a "magic predicate" (B<apf:strSplit> in TARQL or B<spif:split> in Ontotext Refine) to split x and produce multiple bindings

=item * B<COALESCE(x,...)> uses B<__VA_ARGS__> to take any number of arguments (variadic arguments)

=item * B<SPLIT(x,"\\\\")> escapes backslash twice: once for a SPARQL string, and a second time for the regular expression taht it represents

=item * B<_IF_BOUND(x,...)> is a complex macro. See its definition in section Conditional Nodes

=back


=head3 Macro Best Practices

To save yourself some trouble, here are some hints for writing and using macros:

=over

=item * Write builtin SPARQL functions in lowercase to avoid mistaking them for macro definitions

=item * To implement B<SPLIT>, use B<apf:strSplit> in TARQL and B<spif:split> in Ontotext Refine. (In a future version, this tool may take care of that difference.)

=item * B<SPLIT> delimiters often use URL-unfriendly chars. So don't use "raw" SPLIT with 2 arguments, but define "business" versions of SPLIT as above.

=item * If you want to put comments in models, use double hash B<##> since the single hash is interpreted as a preprocessor directive (even if there is a space after it)

=back

=head2 Generated SPARQL

The overall structure of the generated SPARQL query depends on the options you used.
Assume the example in section "RDF Model: Annual Revenue by Permalink", which has 2 special features:

=over

=item * The graph is computed from data:
  GRAPH <extra/(permalink)/revenue>

=item * The subject is looked up in the RDF database (see the definition of the respective macro):
  <CB_AGENT_URL(permalink)>
  ->
  filter(bound(?permalink)) ?permalink_CB_AGENT_URL a ?permalink_TYPE; k2:permalink ?permalink filter(?permalink_TYPE in (cb:Person,cb:Organization))

=back

For Ontotext Refine UPDATE:

  delete {graph ?extra_permalink_revenue_URL {?_s_ ?_p_ ?_o_}}
  where {
    service <rdf-mapper:ontorefine:PROJECT_ID> {
      # generated binds
    }
    filter(bound(?permalink)) ?permalink_CB_AGENT_URL a ?permalink_TYPE; cb:permalink ?permalink filter(?permalink_TYPE in (cb:Person,cb:Organization))
    graph ?extra_permalink_revenue_URL {?_s_ ?_p_ ?_o_}};
  insert {graph ?extra_permalink_revenue_URL {
    # insert patterns
  }}
  where {
    service <rdf-mapper:ontorefine:PROJECT_ID> {
      # generated binds
    }
  };

=over

=item * The graph URL pattern mentioned in the first model line is expanded to a calculated variable B<?extra_permalink_revenue_URL>. In this case we use named graph per table B<row>; if you use a constant URL then it would be graph per B<table>. This way the query can handle both initial data loading and updates.

=item * Crunchbase tables include B<updated_at> timestamps in every row that we compare to a global timestamp (recorded in the database) and find only updated rows. This is an extra filter generated by a slightly more complex script (not published).

=item * B<PROJECT_ID> is a placeholder that must be replaced with the actual Ontotext Refine project ID before running the query.

=item * The script has a special case for macro names matching B<*_URL>, that's why the B<CB_AGENT_URL> pattern is evaluated outside of the Ontotext Refine virtual endpoint.

=item * The wildcard pattern B<where {... graph ?extra_permalink_revenue_URL {?_s_ ?_p_ ?_o_}}> selects all triples in the graph, to be deleted

=back

For Ontotext Refine CONSTRUCT:

  construct {
    # insert patterns
  }
  where {
    service <rdf-mapper:ontorefine:PROJECT_ID> {
      # generated binds
    }
    filter(bound(?permalink)) ?permalink_CB_AGENT_URL a ?permalink_TYPE; k2:permalink ?permalink filter(?permalink_TYPE in (cb:Person,cb:Organization))
  }

CONSTRUCT doesn't work with named graphs, so any graph is ignored.

For TARQL CONSTRUCT:

  construct {
    # insert patterns
  }
  where {
    # generated binds
  }

TARQL cannot make a lookup in existing RDF data, so macro names matching B<*_URL> are not allowed.

=head3 Insert Patterns: CrunchBase Organizations

The script unrolls macro (function) calls into binds, adding uppercase suffixes to the variable names.
In addition, it knows how to process templatized URLs (see var names with a B<_URL> suffix)
and how to process datatype attachments (adding the datatype as suffix).
Compare the patterns below to the first model example:

  ?cb_agent_uuid_URL a cb:Organization;
    cb:uuid ?uuid;
    cb:name ?name;
    cb:permalink ?permalink;
    cb:url ?CB_URL;
    cb:rank ?RANK;
    cb:createdAt ?created_at_FIXDATETIME_xsd_dateTime;
    cb:updatedAt ?updated_at_FIXDATETIME_xsd_dateTime;
    cb:legalName ?legal_name;
    cb:organizationRole ?cb_organizationRole_roles_SPLIT_URLIFY_URL;
    cb:domain ?domain;
    cb:homepageUrl ?homepage_url_xsd_anyURI;
    cb:countryCode ?country_code;
    cb:stateCode ?state_code;
    cb:region ?region;
    cb:city ?city;
    cb:address ?address;
    cb:postalCode ?postal_code;
    cb:status ?cb_organizationStatus_status_URLIFY_URL;
    cb:shortDescription ?short_description;
    cb:industry ?cb_industry_category_list_SPLIT1_URLIFY_URL;
    cb:numFundingRounds ?num_funding_rounds_xsd_integer;
    cb:totalFundingUsd ?total_funding_usd_xsd_decimal;
    cb:totalFunding ?total_funding_xsd_decimal;
    cb:totalFundingCurrencyCode ?total_funding_currency_code;
    cb:foundedOn ?founded_on_FIXDATE_xsd_date;
    cb:lastFundingOn ?last_funding_on_FIXDATE_xsd_date;
    cb:closedOn ?closed_on_FIXDATE_xsd_date;
    cb:employeeCount ?cb_employeeCount_employee_count_IFNOTNULL_URLIFY_URL;
    cb:email ?email;
    cb:phone ?phone;
    cb:facebookUrl ?facebook_url_xsd_anyURI;
    cb:linkedinUrl ?linkedin_url_xsd_anyURI;
    cb:twitterUrl ?twitter_url_xsd_anyURI;
    cb:logoUrl ?logo_url_xsd_anyURI;
    cb:alias ?alias1;
    cb:alias ?alias2;
    cb:alias ?alias3;
    cb:primaryRole ?cb_organizationRole_primary_role_URLIFY_URL;
    cb:numExits ?num_exits_xsd_integer.

=head3 Generated Pre-Binds

The script emits a bunch of bindings.

For Ontotext Refine, first come silly "aliases" for each variable used in the model
because of some peculiarities of the Ontotext Refine virtual endpoint
(issue L<GDB-6600|https://ontotext.atlassian.net/browse/GDB-6600>):

    bind(?c_uuid as ?uuid)
    bind(?c_name as ?name)
    bind(?c_permalink as ?permalink)
    bind(?c_cb_url as ?cb_url)
    bind(?c_rank as ?rank)
    bind(?c_created_at as ?created_at)
    bind(?c_updated_at as ?updated_at)
    bind(?c_legal_name as ?legal_name)
    bind(?c_roles as ?roles)
    bind(?c_domain as ?domain)
    bind(?c_homepage_url as ?homepage_url)
    bind(?c_country_code as ?country_code)
    bind(?c_state_code as ?state_code)
    bind(?c_region as ?region)
    bind(?c_city as ?city)
    bind(?c_address as ?address)
    bind(?c_postal_code as ?postal_code)
    bind(?c_status as ?status)
    bind(?c_short_description as ?short_description)
    bind(?c_category_list as ?category_list)
    bind(?c_num_funding_rounds as ?num_funding_rounds)
    bind(?c_total_funding_usd as ?total_funding_usd)
    bind(?c_total_funding as ?total_funding)
    bind(?c_total_funding_currency_code as ?total_funding_currency_code)
    bind(?c_founded_on as ?founded_on)
    bind(?c_last_funding_on as ?last_funding_on)
    bind(?c_closed_on as ?closed_on)
    bind(?c_employee_count as ?employee_count)
    bind(?c_email as ?email)
    bind(?c_phone as ?phone)
    bind(?c_facebook_url as ?facebook_url)
    bind(?c_linkedin_url as ?linkedin_url)
    bind(?c_twitter_url as ?twitter_url)
    bind(?c_logo_url as ?logo_url)
    bind(?c_alias1 as ?alias1)
    bind(?c_alias2 as ?alias2)
    bind(?c_alias3 as ?alias3)
    bind(?c_primary_role as ?primary_role)
    bind(?c_num_exits as ?num_exits)

=head3 Generated Binds: CrunchBase Organizations

Then come a number of bindings generated by:

=over

=item * Handling templated URLs (eg B<?cb_agent_uuid_URL>),

=item * Unrolling macro (function) calls into binds and suffixed variables (eg B<?roles_SPLIT> and then B<?roles_SPLIT_URLIFY>)

=item * Implementing datatype casting using B<strdt()> and binding to an uppercased variable name (eg B<?CB_URL, ?RANK>)

=back

  bind(iri(concat("cb/agent/",?uuid)) as ?cb_agent_uuid_URL)
  bind(strdt(?cb_url,xsd:anyURI) as ?CB_URL)
  bind(strdt(?rank,xsd:integer) as ?RANK)
  bind(replace(?created_at,' ','T') as ?created_at_FIXDATETIME)
  bind(strdt(?created_at_FIXDATETIME,xsd:dateTime) as ?created_at_FIXDATETIME_xsd_dateTime)
  bind(replace(?updated_at,' ','T') as ?updated_at_FIXDATETIME)
  bind(strdt(?updated_at_FIXDATETIME,xsd:dateTime) as ?updated_at_FIXDATETIME_xsd_dateTime)
  ?roles_SPLIT_COMMA spif:split (?roles ',').
  bind(lcase(replace(replace(replace(?roles_SPLIT_COMMA, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?roles_SPLIT_COMMA_URLIFY)
  bind(iri(concat("cb/organizationRole/",?roles_SPLIT_COMMA_URLIFY)) as ?cb_organizationRole_roles_SPLIT_COMMA_URLIFY_URL)
  bind(strdt(?homepage_url,xsd:anyURI) as ?homepage_url_xsd_anyURI)
  bind(lcase(replace(replace(replace(?status, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?status_URLIFY)
  bind(iri(concat("cb/organizationStatus/",?status_URLIFY)) as ?cb_organizationStatus_status_URLIFY_URL)
  ?category_list_SPLIT_COMMA spif:split (?category_list ',').
  bind(lcase(replace(replace(replace(?category_list_SPLIT_COMMA, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?category_list_SPLIT_COMMA_URLIFY)
  bind(iri(concat("cb/industry/",?category_list_SPLIT_COMMA_URLIFY)) as ?cb_industry_category_list_SPLIT_COMMA_URLIFY_URL)
  bind(strdt(?num_funding_rounds,xsd:integer) as ?num_funding_rounds_xsd_integer)
  bind(strdt(?total_funding_usd,xsd:decimal) as ?total_funding_usd_xsd_decimal)
  bind(strdt(?total_funding,xsd:decimal) as ?total_funding_xsd_decimal)
  bind(replace(?founded_on,' ','T') as ?founded_on_FIXDATETIME)
  bind(strdt(?founded_on_FIXDATETIME,xsd:dateTime) as ?founded_on_FIXDATETIME_xsd_dateTime)
  bind(replace(?last_funding_on,' ','T') as ?last_funding_on_FIXDATETIME)
  bind(strdt(?last_funding_on_FIXDATETIME,xsd:dateTime) as ?last_funding_on_FIXDATETIME_xsd_dateTime)
  bind(replace(?closed_on,' ','T') as ?closed_on_FIXDATETIME)
  bind(strdt(?closed_on_FIXDATETIME,xsd:dateTime) as ?closed_on_FIXDATETIME_xsd_dateTime)
  bind(if(?employee_count in ("other","not provided","unknown"),?UNDEF,?employee_count) as ?employee_count_IFNOTNULL)
  bind(lcase(replace(replace(replace(?employee_count_IFNOTNULL, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?employee_count_IFNOTNULL_URLIFY)
  bind(iri(concat("cb/employeeCount/",?employee_count_IFNOTNULL_URLIFY)) as ?cb_employeeCount_employee_count_IFNOTNULL_URLIFY_URL)
  bind(strdt(?facebook_url,xsd:anyURI) as ?facebook_url_xsd_anyURI)
  bind(strdt(?linkedin_url,xsd:anyURI) as ?linkedin_url_xsd_anyURI)
  bind(strdt(?twitter_url,xsd:anyURI) as ?twitter_url_xsd_anyURI)
  bind(strdt(?logo_url,xsd:anyURI) as ?logo_url_xsd_anyURI)
  bind(lcase(replace(replace(replace(?primary_role, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?primary_role_URLIFY)
  bind(iri(concat("cb/organizationRole/",?primary_role_URLIFY)) as ?cb_organizationRole_primary_role_URLIFY_URL)
  bind(strdt(?num_exits,xsd:integer) as ?num_exits_xsd_integer)

=head3 Generated Binds: Customers

For the Customers example, the binds are pretty similar,
but we use a slightly different definition of B<URLIFY> (uses teh Unicode Numeric character class B<\p{N}> instead of B<0-9>).

  bind(iri(concat("person/",?customer_id)) as ?person_URL)
  bind(iri(concat("person/",?customer_id,"/address")) as ?person_address_URL)
  bind(iri(concat("person/",?customer_id,"/birth")) as ?person_birth_URL)
  bind(iri(concat("person/",?customer_id,"/education")) as ?person_education_URL)
  bind(replace(replace(replace(?city,'[^\\p{L}\\p{N}]+','_'),'^_',''),'_$','') as ?city_URLIFY)
  bind(iri(concat("country/",?country,"/city/",?city_URLIFY)) as ?country_city_URLIFY_URL)
  bind(iri(concat("country/",?country)) as ?country_URL)
  bind(strdt(?date_of_birth,xsd:date) as ?date_of_birth_xsd_date)
  bind(strdt(?enrollment_date,xsd:date) as ?enrollment_DATE_xsd_date)
  bind(replace(replace(replace(?university,'[^\\p{L}\\p{N}]+','_'),'^_',''),'_$','') as ?university_URLIFY)
  bind(iri(concat("university/",university_URLIFY)) as ?university_URLIFY_URL)
  bind(replace(replace(replace(?education_degree,'[^\\p{L}\\p{N}]+','_'),'^_',''),'_$','') as ?education_degree_URLIFY)
  bind(iri(concat("degree/",?education_degree_URLIFY)) as ?education_degree_URLIFY

=head3 Generated Update: Annual Revenue by Permalink

This model adds some extra Revenue triples into a specified named graph.
The overall Ontotext Refine UPDATE looks like this:

  delete where {graph <extra/revenue> {?x ?p ?o}};
  insert {graph  <extra/revenue> {
    ?permalink_CB_AGENT_URL ex:annualRevenueUsd ?revenue_xsd_decimal
  }}
  where {
    service <rdf-mapper:ontorefine:PROJECT_ID> {
      bind(?c_revenue as ?revenue)
      bind(strdt(?revenue,xsd:decimal) as ?revenue_xsd_decimal)
    }
    filter(bound(?permalink))
    ?permalink_CB_AGENT_URL a ?permalink_TYPE; k2:permalink ?permalink
    filter(?permalink_TYPE in (cb:Person,cb:Organization))
  };

As you can see, the B<CB_AGENT_URL> macro is evaluated outside of the Ontotext Refine virtual endpoint.

=head3 Generated Binds: Spending Categories

  bind(iri(concat("grant/",?APPLICATION_ID)) as ?grant_APPLICATION_ID_URL)
  ?NIH_SPENDING_CATS_SPLIT apf:strSplit (?NIH_SPENDING_CATS "; ?").
  bind(replace(replace(replace(?NIH_SPENDING_CATS_SPLIT_SEMI, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "") as ?NIH_SPENDING_CATS_SPLIT_SEMI_URLIFY)
  bind(iri(concat("spendingCategory/",?NIH_SPENDING_CATS_SPLIT_SEMI_URLIFY)) as ?spendingCategory_NIH_SPENDING_CATS_SPLIT_SEMI_URLIFY_URL)


=head1 SEE ALSO

B<test/graphs-crunchbase> for the worked example of generating a SPARQL Update for CrunchBase organizations with dynamic (computed) graph.

The gist L<CrunchBase Semantic Model and Challenge|https://gist.github.com/VladimirAlexiev/d5d67feb002dbcfa6b3d4c3dd59b52da> that publishes all our CrunchBase models.
It also shows an overall model diagram made by B<rdfpuml>.

The issue L<Generate Transforms and Shapes from Models|https://github.com/kg-construct/best-practices/issues/7> in the Knowledge Graph Construct W3C community group "Best Practices" github project.

B<rdfpuml>: a tool that generates PlantUML diagrams from RDF examples.

B<rdf2rml>: a tool that generates R2RML transformations from RDF examples.

B<rdf2tarql>: a tool that generates TARQL queries from RDF examples.

=head1 AUTHOR

Vladimir Alexiev, Ontotext Corp

Last update:  8-Dec-2022
