NAME
    rdf2sparql - Convert RDF examples to SPARQL queries (OntoRefine or
    TARQL)

SYNOPSIS
      perl rdf2sparql.pl             model.ttl | cat common.h prefixes.rq - | cpp -P -C -nostdinc - > model-ontorefine.ru
      perl rdf2sparql.pl --construct model.ttl | cat common.h prefixes.rq - | cpp -P -C -nostdinc - > model-ontorefine.rq
      perl rdf2sparql.pl --tarql     model.ttl | cat common.h prefixes.rq - | cpp -P -C -nostdinc - > model.tarql

      Options:
        --construct: generate CONSTRUCT query (default is UPDATE; applies only for OntoRefine)
        --tarql: generate for TARQL (default is OntoRefine)

DESCRIPTION
    rdf2sparql converts an RDF example with embedded CSV/TSV column names
    into a SPARQL query for:

    *   TARQL <https://tarql.github.io/>, which is a is a high-speed
        streaming convertor. It's a SPARQL processor for tabular data, where
        each column col of each row is exposed as a variable binding ?col
        (punctuation is replaced with underscores). See releases
        <https://github.com/tarql/tarql/releases>, tested with version
        1.2-SNAPSHOT, BUILD_DATE: 2017-12-07T13:33:10Z

    *   OntoRefine
        <https://graphdb.ontotext.com/documentation/standard/loading-data-us
        ing-ontorefine.html>, which is an adaptation of OpenRefine for
        working with RDF data. It exposes a table as a virtual SPARQL
        endpoint (special service), where each column col of each row is
        exposed as a variable binding ?c_col.

    We've used TARQL to convert large files (over 10M rows, 145 columns)
    using complex TARQL queries (480 lines: 110 prefixes, 33 nodes, 250
    triples, 110 binds).

    We've used OntoRefine for large and complex CSV files, e.g. Crunchbase
    consisting of 18 tables, total 10.5M rows, 318 columns; for both initial
    loading and data updates. See CrunchBase Challenge
    <https://gist.github.com/VladimirAlexiev/d5d67feb002dbcfa6b3d4c3dd59b52d
    a> for details. (Please note that we use a customized script that works
    with named graph per table row, not per table.)

  Options
    The default is to generate a SPARQL UPDATE query for OntoRefine. It
    encloses OntoRefine variables in a service clause that accesses the
    OntoRefine virtual SPARQL endpoint (see later about the handling of
    PROJECT_ID):

      service <rdf-mapper:ontorefine:PROJECT_ID> {
        ...
      }

    This has several benefits:

    *   It ingests directly to GraphDB (without producing an intermediate
        RDF file), which is faster.

    *   It overwrites a named graph, so it can be used for ingest or update.
        The first model line must look like this where graph is the graph to
        overwrite (in angle brackets).

          ## GRAPH <graph>

    *   You can match real triples in GraphDB, which can be used to resolve
        entities ("strings" to "things"). A macro name that ends in "URL"
        (case-insensitively), e.g. CB_AGENT_URL(permalink), causes the
        respective patterns to be interpreted outside of the OntoRefine
        virtual service.

    *   You can split several multi-valued columns (using the SPLIT macro)
        to produce multiple bindings, without fear of Cartesian Product
        (i.e. their values will not be combined with each other).

    Option -construct generates a SPARQL CONSTRUCT query. You can still
    match GraphDB triples and use multiple multi-valued columns. Any GRAPH
    comment is ignored, because CONSTRUCT does not support graphs (see
    SPARQL 1.2 issue 31 <https://github.com/w3c/sparql-12/issues/31>). The
    query produces intermediate RDF data that must be saved before loading
    to GraphDB, then you can use the SPARQL Graph Store Protocol
    <https://www.w3.org/TR/sparql11-http-rdf-update/> to overwrite the
    respective graph.

    Option --tarql generates a TARQL CONSTRUCT query. You should put each
    multivalued column (together with the primary key column) in a distinct
    model to avoid Cartesian Product. You cannot match RDF data in a
    repository (see TARQL issue 25
    <https://github.com/tarql/tarql/issues/25>), use UPDATE (see TARQL issue
    67 <https://github.com/tarql/tarql/issues/67>), nor use graphs (see
    TARQL issue 98 <https://github.com/tarql/tarql/issues/98>).

    You can abbreviate options. All these are equivalent:

      --c --co --construct
      --t --ta --tarql

  Prerequisites
    *   OntoRefine or TARQL as described above

    *   Perl. Tested with 5.32.1 (Straberry Perl on Cygwin)

    *   Working CPP preprocessor. Tested with 8.3.0 (x86_64-posix-seh, Built
        by strawberryperl.com project)

    *   A file (eg prefixes.rq) that defines all common prefixes and is
        prepended to the generated query

    *   A file (eg common.h) that defines CPP preprocessor macros

  Process
    *   Make a rdfpuml semantic model for a single table, using field names
        as parenthesized embeds. See below for several examples.

    *   Run the script followed by the CPP proprocessor as shown above and
        save the SPARQL script

    To process CSV/TSV with the generated SPARQL scripts, use the following
    steps.

    Process with model.tarql (variants for CSV or TSV):

      tarql    model.tarql data.csv > data.ttl
      tarql -t model.tarql data.tsv > data.ttl

    Process model-ontorefine.ru with OntoRefine:

    *   Create a project, load tabular data

    *   Optionally, perform data cleaning

    *   Make sure you have a working GraphDB repository to receive the data

    *   Paste the generated SPARQL into GraphDB workbench and adjust
        PROJECT_ID to the actual Refine virtual endpoint and project ID

    *   Run the query to update the data in GraphDB

    If you save the OntoRefine cleaning script (operations JSON), you can
    automate the OntoRefine process by using the ontorefine-client
    <https://github.com/Ontotext-AD/ontorefine-client> CLI (it will become
    part of the OntoRefine distribution). We have scripts to automate the
    following steps:

    *   Create an OntoRefine project and capture its project ID

    *   Load tabular data into the OntoRefine project

    *   Optionally, apply an OpenRefine data cleaning script

    *   Replace the placeholder PROJECT_ID in the generated query with the
        actual ID

    *   Run the query against a GraphDB repository: it will replace the
        defined named graph

    *   Delete the OntoRefine project

  RDF Model Examples
    rdfpuml models are RDF Turtle examples that use parenthesized column
    names in URLs ("templated URLs") and in attribute values (which can be
    datatyped).

    They are valid Turtle, with the exception that RDF tools issue warnings
    about templated literals such as "(some_date)"^^xsd:date or
    "(amount)"^^xsd:decimal.

    You can also use "functions" that you need to implement as CPP macros.
    rdf2sparql takes care to unroll the functions into BINDs, adding
    suffixes to variable names.

    See also test/customer for a separate example (includes a Makefile).

   RDF Model: CrunchBase Organizations
    The first example is a simple semantic representation of Crunchbase's
    organizations.csv table:

      ## GRAPH <cb/graph/organizations>
  
      <cb/agent/(uuid)> a cb:Organization;
        cb:uuid '(uuid)';
        cb:name '(name)';
        cb:permalink '(permalink)';
        cb:url '(cb_url)'^^xsd:anyURI;
        cb:rank '(rank)'^^xsd:integer;
        cb:createdAt 'FIXDATE(created_at)'^^xsd:dateTime;
        cb:updatedAt 'FIXDATE(updated_at)'^^xsd:dateTime;
        cb:legalName '(legal_name)';
        cb:organizationRole <cb/organizationRole/URLIFY(SPLIT_COMMA(roles))>;
        cb:domain '(domain)';
        cb:homepageUrl '(homepage_url)'^^xsd:anyURI;
        cb:countryCode '(country_code)';
        cb:stateCode '(state_code)';
        cb:region '(region)';
        cb:city '(city)';
        cb:address '(address)';
        cb:postalCode '(postal_code)';
        cb:status <cb/organizationStatus/URLIFY(status)>;
        cb:shortDescription '(short_description)';
        cb:industry <cb/industry/URLIFY(SPLIT_COMMA(category_list))>;
        cb:numFundingRounds '(num_funding_rounds)'^^xsd:integer;
        cb:totalFundingUsd '(total_funding_usd)'^^xsd:decimal;
        cb:totalFunding '(total_funding)'^^xsd:decimal;
        cb:totalFundingCurrencyCode '(total_funding_currency_code)';
        cb:foundedOn 'FIXDATE(founded_on)'^^xsd:dateTime;
        cb:lastFundingOn 'FIXDATE(last_funding_on)'^^xsd:dateTime;
        cb:closedOn 'FIXDATE(closed_on)'^^xsd:dateTime;
        cb:employeeCount <cb/employeeCount/URLIFY(IFNOTNULL(employee_count))>;
        cb:email '(email)';
        cb:phone '(phone)';
        cb:facebookUrl '(facebook_url)'^^xsd:anyURI;
        cb:linkedinUrl '(linkedin_url)'^^xsd:anyURI;
        cb:twitterUrl '(twitter_url)'^^xsd:anyURI;
        cb:logoUrl '(logo_url)'^^xsd:anyURI;
        cb:alias '(alias1)';
        cb:alias '(alias2)';
        cb:alias '(alias3)';
        cb:primaryRole <cb/organizationRole/URLIFY(primary_role)>;
        cb:numExits '(num_exits)'^^xsd:integer.

    It puts all fields in one table and uses macros like URLIFY to make a
    phrase usable in URL, IFNOTNULL to discard parasitic phrases, SPLIT to
    split a multi-valued field into multiple bindings, etc. It uses a GRAPH
    comment to specify which named graph should be overwritten.

   RDF Model: Customers
    Next is an example about persons (customers).

        <person/(customer_id)> a :NaturalPerson;
          :id "(customer_id)";
          :firstName "(first_name)";
          :lastName "(last_name)";
          :gender "(gender)";
          :religion "(religion)";
          :hasAddress <person/(customer_id)/address>;
          :hasEvent  <person/(customer_id)/birth>;
          :hasEvent  <person/(customer_id)/education>.

        <person/(customer_id)/address> a :Address;
          :houseNumber "(house_number)";
          :street "(street)";
          :postalCode "(postal_code)";
          :city <country/(country)/city/URLIFY(city)>;
          :country <country/(country)>.

        <country/(country)/city/URLIFY(city)> a :City; :country <country/(country)>; :name "(city)".

        <country/(country)> a :Country; :code "(country)".

        <person/(customer_id)/birth> a :BirthEvent; :hasDate "(date_of_birth)"^^xsd:date.

        <person/(customer_id)/education> a :EducationEvent;
          :hasDate "(enrollment_date)"^^xsd:date;
          :university <university/URLIFY(university)>;
          :degree <degree/URLIFY(education_degree)>.

    It dispatches fields to several nodes and uses only one macro (URLIFY).

   RDF Model: Annual Revenue by Permalink
    Next is a very simple model that adds "revenue" into to CrunchBase
    organizations.

      ## GRAPH <extra/revenue>
      <CB_AGENT_URL(permalink)> ex:annualRevenueUsd "(revenue)"^^xsd:decimal.

    The revenue is keyed by "permalink" so we use the CB_AGENT_URL() macro
    to lookup by permalink.

   RDF Model: Grant Spending Categories
    This model of NIH grants assumes that an application (with primary key
    APPLICATION_ID) can have multiple spending categories (field
    NIH_SPENDING_CATS) separated by semi-colon. To avoid Cartesian Product
    with TARQL, we put this one field in a separate model file:

      <grant/(APPLICATION_ID)> gr:spendingCategory <spendingCategory/URLIFY(SPLIT_SEMI(NIH_SPENDING_CATS))>.

      <spendingCategory/URLIFY(SPLIT_SEMI(NIH_SPENDING_CATS))>
        a skos:Concept ;
        skos:inScheme  <spendingCategory> ;
        skos:prefLabel "SPLIT_SEMI(NIH_SPENDING_CATS)".

      <spendingCategory>
        a skos:ConceptScheme ;
        skos:prefLabel  "NIH spending category".

    Note that in addition to making the gr:spendingCategory relation, this
    model also emits extra nodes. This will lead to redundant triples: each
    individual skos:Concept is duplicated as many times as it's used in
    grants, and skos:ConceptScheme is duplicated as the total number of
    grants.

    This does not lead to conflicts since the same triple cannot be recorded
    multiple times in an RDF repository. However, if this data redundancy is
    bothersome, you can normalize the Concept data to a separate file of
    unique concepts; and move the ConceptScheme into a separate "constant"
    RDF file that doesn't need to be processed with rdf2sparql.

   RDF Model Concatenation
    rdf2sparql works on a single CSV table at a time (rdf2rml does not have
    this limitation). Furthermore, as seen above, you may need to split a
    model into "component" sub-models to handle multi-valued columns. Making
    diagrams from such tiny models is not very useful.

    Luckily, concatenating several Turtle files is also a valid Turtle. So
    you can make an overall model by concatenating the component models.

    Here is a Makefile from a recent project. It specifies how to make the
    overall nih-model.ttl, and then the diagram nih-model.png from it.

      all: nih-model.ttl nih-model.png prefixes.rq

      nih-model.ttl: prefixes.ttl nih-activityType.ttl nih-applicationType.ttl nih-department.ttl \
        nih-funder.ttl nih-funding.ttl nih-fundingMechanism.ttl nih-grant.ttl nih-linkClinicalStudy.ttl \
        nih-linkPatent.ttl nih-linkPublication.ttl nih-principalInvestigator.ttl nih-researcher.ttl \
        nih-spendingCategory.ttl nih-studySection.ttl puml.ttl
              cat $^ | perl nih-model-rename.pl > $@

      %.png: %.ttl
              rdfpuml.bat $*.ttl
              puml.bat $*.puml
              rm $*.puml

      prefixes.rq: prefixes.ttl
              perl -pe 'm{###} and last; s{^@}{}; s{ *\.$$}{}' $^ > $@

    It uses a shared prefixes.ttl and its SPARQL variant prefixes.rq that is
    prepended to any generated query. To ensure connectivity of the overall
    model, a script like nih-model-rename.pl renames URLs in object position
    ("foreign keys") to respective URLs in subject position ("primary
    keys"), e.g.:

      #!perl -p

      s{\Q/FIND_CONTACT(PI_IDS)}{/(PI_ID)};
      s{\Q/OMIT_CONTACT(PI_IDS)}{/(PI_ID)};
      s{\Q/FUNDER(FUNDING_ICs)}{/(FUNDING_IC)};

  Preprocessor Macros
    In addition to plain CSV field names you can also use macros ("function
    calls") that are unrolled by the script into a series of binds using
    suffixed variable names. Below are some examples we've used in various
    projects. These are implemented as CPP preprocessor macro definitions
    (e.g. in file common.h):

    *   make a name usable in URL. Replace punctuations with one underscore;
        remove leading/trailing punctuation. Support all Unicode
        alphanumeric chars. Convert alphabetical to lowercase.

          #define URLIFY1(x)      lcase(replace(replace(replace(x, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", ""))

    *   same but also generates a bind to x_URLIFY

          #define URLIFY(x)       bind(URLIFY1(x) as x##_URLIFY)

    *   replace space with "T" in a timestamp to conform to xsd:dateTime
        format

          #define FIXDATETIME(x)  bind(replace(x,' ','T') as x##_FIXDATETIME)

    *   convert dates from mm/dd/yyyy to yyyy-mm-dd to conform to xsd:date
        forma

          #define FIXDATE(x)      bind(replace(x,"(..)/(..)/(....)","$3-$1-$2") as x##_FIXDATE)

    *   lookup a CrunchBase permalink to find the respective agent
        (organization or person) URL

          #define CB_AGENT_URL(x) filter(bound(x)) x##_CB_AGENT_URL a x##_TYPE; k2:permalink x filter(x##_TYPE in (cb:Person,cb:Organization))

    *   filter out parasitic values ("other","not provided","unknown")

          #define IFNOTNULL(x)    bind(if(x in ("other","not provided","unknown"),?UNDEF,x) as x##_IFNOTNULL)

    *   filter out x values that are equal to ?y. Used to strip
        self-referential parent: CB category mentioning itself as
        category_group

          #define IFNOTSAME(x,y)  bind(if(x=y,?UNDEF,x) as x##_IFNOTSAME)

    *   assign the first bound variable amongst the ... arguments to
        variable x##_COALESCE

          #define COALESCE(x,...) bind(coalesce(__VA_ARGS__) as x##_COALESCE)

    *   map "Yes","No" to "true","false" respectively

          #define YESNO(x)        bind(if(x="Yes",true,false) as x##_YESNO)

    *   split x on a given delimiter y and produce multiple bindings in
        variable z

          #define SPLIT(x,y,z)    z apf:strSplit (x y).

    *   split on semicolon (optionally followed by space) and produce
        multiple bindings.

          #define SPLIT_SEMI(x)   SPLIT(x,"; ?",x##_SPLIT_SEMI)

    *   split on comma (optionally followed by space) and produce multiple
        bindings.

          #define SPLIT_COMMA(x)  SPLIT(x,", ?",x##_SPLIT_COMMA)

    *   find a numeric identifier element marked as " (contact)"

          #define FIND_CONTACT(x) bind(replace(x, ".*?([0-9]+) \\(contact\\).*", "$1") as x##_FIND_CONTACT)

    *   split on semicolon and return all numeric identifiers except the one
        marked as " (contact)"

          #define OMIT_CONTACT(x) SPLIT_SEMI(x)  bind(if(regex(x##_SPLIT_SEMI,"^$| \\(contact\\)",?UNDEF,x##_SPLIT_SEMI) as x##_OMIT_CONTACT)

    *   split on backslash then return the first :-delimited part of each
        pair (funder code)

          #define FUNDER(x)       SPLIT(x,"\\\\",x##_SPLIT_BACKSL) bind(replace(x##_SPLIT_BACKSL,"(.+):(.+)","$1") as x##_FUNDER)

    *   return the second :-delimited part of each pair (amount). Must be
        used together with FUNDER(x) because it uses x##_SPLIT_BACKSL
        without binding it

          #define AMOUNT(x)                                        bind(replace(x##_SPLIT_BACKSL,"(.+):(.+)","$2") as x##_AMOUNT)

    Most of the macros implement binds (computations), but you can also use
    more specialized constructs. Notes about unusual constructs:

    *   URLIFY1(x) uses the Unicode character class \p{L} for "Letters"

    *   IFNOTNULL(x) and IFNOTSAME(x) use a conditional and the variable
        ?UNDEF, which by convention is never bound, so is undefined

    *   ## concatenates two preprocessor tokens (a variable name and a
        constant string) to make a new variable name

    *   CB_AGENT_URL(x): uses a real RDF lookup (outside of the OntoRefine
        virtual endpoint). Before that guards with bound(x) (otherwise an
        unbound variable will return all agents), then checks for respective
        rdf:type

    *   SPLIT(x): uses a "magic predicate" (apf:strSplit in TARQL or
        spif:split in OntoRefine) to split x and produce multiple bindings

    *   COALESCE(x,...) uses __VA_ARGS__ to take any number of arguments
        (variadic arguments)

    *   SPLIT(x,"\\\\") escapes backslash twice: once for a SPARQL string,
        and a second time for the regular expression taht it represents

   Macro Best Practices
    To save yourself some trouble, here are some hints for writing and using
    macros:

    *   Write builtin SPARQL functions in lowercase to avoid mistaking them
        for macro definitions

    *   To implement SPLIT, use apf:strSplit in TARQL and spif:split in
        OntoRefine. (In a future version, this tool may take care of that
        difference.)

    *   SPLIT delimiters often use URL-unfriendly chars. So don't use "raw"
        SPLIT with 2 arguments, but define "business" versions of SPLIT as
        above.

    *   If you want to put comments in models, use double hash ## since the
        single hash is interpreted as a preprocessor directive (even if
        there is a space after it)

  Generated SPARQL
    The overall structure of the generated SPARQL query depends on the
    options you used.

    For OntoRefine UPDATE:

      delete where {graph $GRAPH {?s ?p ?o}};
      insert {graph $GRAPH {
        <Insert Patterns>
      }}
      where {
        service <rdf-mapper:ontorefine:PROJECT_ID> {
          <Generated Binds>
        }
        filter(bound(?permalink))
        ?permalink_CB_AGENT_URL a ?permalink_TYPE; cb:permalink ?permalink
        filter(?permalink_TYPE in (cb:Person,cb:Organization))
      };

    *   $GRAPH is the named graph mentioned in the first model line. This
        way the query can handle both initial data loading and updates.
        Please note that for Crunchbase it is unfeasible to regenerate all
        Organization data on every update. So we have a slightly more
        complex script (not published) that uses a named graph per table row
        (uuid) not per table, and selects only recently updated rows for
        processing.

    *   PROJECT_ID is a placeholder that must be replaced with the actual
        OntoRefine project ID before running the query.

    *   The script has a special case for macro names matching *_URL, that's
        why the CB_AGENT_URL pattern is evaluated outside of the OntoRefine
        virtual endpoint.

    For OntoRefine CONSTRUCT:

      construct {
        <Insert Patterns>
      }
      where {
        service <rdf-mapper:ontorefine:PROJECT_ID> {
          <Generated Binds>
        }
        filter(bound(?permalink))
        ?permalink_CB_AGENT_URL a ?permalink_TYPE; k2:permalink ?permalink
        filter(?permalink_TYPE in (cb:Person,cb:Organization))
      }

    CONSTRUCT doesn't work with named graphs, so any graph is ignored.

    For TARQL CONSTRUCT:

      construct {
        <Insert Patterns>
      }
      where {
        <Generated Binds>
      }

    TARQL cannot make a lookup in existing RDF data, so macro names matching
    *_URL are not allowed.

   Insert Patterns: Crunchbase Organizations
    The script unrolls macro (function) calls into binds, adding uppercase
    suffixes to the variable names. In addition, it knows how to process
    templatized URLs (see var names with a _URL suffix) and how to process
    datatype attachments (adding the datatype as suffix). Compare the
    patterns below to the first model example:

      ?cb_agent_uuid_URL a cb:Organization;
        cb:uuid ?uuid;
        cb:name ?name;
        cb:permalink ?permalink;
        cb:url ?CB_URL;
        cb:rank ?RANK;
        cb:createdAt ?created_at_FIXDATETIME_xsd_dateTime;
        cb:updatedAt ?updated_at_FIXDATETIME_xsd_dateTime;
        cb:legalName ?legal_name;
        cb:organizationRole ?cb_organizationRole_roles_SPLIT_URLIFY_URL;
        cb:domain ?domain;
        cb:homepageUrl ?homepage_url_xsd_anyURI;
        cb:countryCode ?country_code;
        cb:stateCode ?state_code;
        cb:region ?region;
        cb:city ?city;
        cb:address ?address;
        cb:postalCode ?postal_code;
        cb:status ?cb_organizationStatus_status_URLIFY_URL;
        cb:shortDescription ?short_description;
        cb:industry ?cb_industry_category_list_SPLIT1_URLIFY_URL;
        cb:numFundingRounds ?num_funding_rounds_xsd_integer;
        cb:totalFundingUsd ?total_funding_usd_xsd_decimal;
        cb:totalFunding ?total_funding_xsd_decimal;
        cb:totalFundingCurrencyCode ?total_funding_currency_code;
        cb:foundedOn ?founded_on_FIXDATE_xsd_date;
        cb:lastFundingOn ?last_funding_on_FIXDATE_xsd_date;
        cb:closedOn ?closed_on_FIXDATE_xsd_date;
        cb:employeeCount ?cb_employeeCount_employee_count_IFNOTNULL_URLIFY_URL;
        cb:email ?email;
        cb:phone ?phone;
        cb:facebookUrl ?facebook_url_xsd_anyURI;
        cb:linkedinUrl ?linkedin_url_xsd_anyURI;
        cb:twitterUrl ?twitter_url_xsd_anyURI;
        cb:logoUrl ?logo_url_xsd_anyURI;
        cb:alias ?alias1;
        cb:alias ?alias2;
        cb:alias ?alias3;
        cb:primaryRole ?cb_organizationRole_primary_role_URLIFY_URL;
        cb:numExits ?num_exits_xsd_integer.

   Generated Pre-Binds
    The script emits a bunch of bindings.

    For OntoRefine, first come silly "aliases" for each variable used in the
    model because of some peculiarities of the OntoRefine virtual endpoint
    (issue GDB-6600 <https://ontotext.atlassian.net/browse/GDB-6600>):

        bind(?c_uuid as ?uuid)
        bind(?c_name as ?name)
        bind(?c_permalink as ?permalink)
        bind(?c_cb_url as ?cb_url)
        bind(?c_rank as ?rank)
        bind(?c_created_at as ?created_at)
        bind(?c_updated_at as ?updated_at)
        bind(?c_legal_name as ?legal_name)
        bind(?c_roles as ?roles)
        bind(?c_domain as ?domain)
        bind(?c_homepage_url as ?homepage_url)
        bind(?c_country_code as ?country_code)
        bind(?c_state_code as ?state_code)
        bind(?c_region as ?region)
        bind(?c_city as ?city)
        bind(?c_address as ?address)
        bind(?c_postal_code as ?postal_code)
        bind(?c_status as ?status)
        bind(?c_short_description as ?short_description)
        bind(?c_category_list as ?category_list)
        bind(?c_num_funding_rounds as ?num_funding_rounds)
        bind(?c_total_funding_usd as ?total_funding_usd)
        bind(?c_total_funding as ?total_funding)
        bind(?c_total_funding_currency_code as ?total_funding_currency_code)
        bind(?c_founded_on as ?founded_on)
        bind(?c_last_funding_on as ?last_funding_on)
        bind(?c_closed_on as ?closed_on)
        bind(?c_employee_count as ?employee_count)
        bind(?c_email as ?email)
        bind(?c_phone as ?phone)
        bind(?c_facebook_url as ?facebook_url)
        bind(?c_linkedin_url as ?linkedin_url)
        bind(?c_twitter_url as ?twitter_url)
        bind(?c_logo_url as ?logo_url)
        bind(?c_alias1 as ?alias1)
        bind(?c_alias2 as ?alias2)
        bind(?c_alias3 as ?alias3)
        bind(?c_primary_role as ?primary_role)
        bind(?c_num_exits as ?num_exits)

   Generated Binds: CrunchBase Organizations
    Then come a number of bindings generated by:

    *   Handling templated URLs (eg ?cb_agent_uuid_URL),

    *   Unrolling macro (function) calls into binds and suffixed variables
        (eg ?roles_SPLIT and then ?roles_SPLIT_URLIFY)

    *   Implementing datatype casting using strdt() and binding to an
        uppercased variable name (eg ?CB_URL, ?RANK)

      bind(iri(concat("cb/agent/",?uuid)) as ?cb_agent_uuid_URL)
      bind(strdt(?cb_url,xsd:anyURI) as ?CB_URL)
      bind(strdt(?rank,xsd:integer) as ?RANK)
      bind(replace(?created_at,' ','T') as ?created_at_FIXDATETIME)
      bind(strdt(?created_at_FIXDATETIME,xsd:dateTime) as ?created_at_FIXDATETIME_xsd_dateTime)
      bind(replace(?updated_at,' ','T') as ?updated_at_FIXDATETIME)
      bind(strdt(?updated_at_FIXDATETIME,xsd:dateTime) as ?updated_at_FIXDATETIME_xsd_dateTime)
      ?roles_SPLIT_COMMA spif:split (?roles ',').
      bind(lcase(replace(replace(replace(?roles_SPLIT_COMMA, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?roles_SPLIT_COMMA_URLIFY)
      bind(iri(concat("cb/organizationRole/",?roles_SPLIT_COMMA_URLIFY)) as ?cb_organizationRole_roles_SPLIT_COMMA_URLIFY_URL)
      bind(strdt(?homepage_url,xsd:anyURI) as ?homepage_url_xsd_anyURI)
      bind(lcase(replace(replace(replace(?status, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?status_URLIFY)
      bind(iri(concat("cb/organizationStatus/",?status_URLIFY)) as ?cb_organizationStatus_status_URLIFY_URL)
      ?category_list_SPLIT_COMMA spif:split (?category_list ',').
      bind(lcase(replace(replace(replace(?category_list_SPLIT_COMMA, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?category_list_SPLIT_COMMA_URLIFY)
      bind(iri(concat("cb/industry/",?category_list_SPLIT_COMMA_URLIFY)) as ?cb_industry_category_list_SPLIT_COMMA_URLIFY_URL)
      bind(strdt(?num_funding_rounds,xsd:integer) as ?num_funding_rounds_xsd_integer)
      bind(strdt(?total_funding_usd,xsd:decimal) as ?total_funding_usd_xsd_decimal)
      bind(strdt(?total_funding,xsd:decimal) as ?total_funding_xsd_decimal)
      bind(replace(?founded_on,' ','T') as ?founded_on_FIXDATETIME)
      bind(strdt(?founded_on_FIXDATETIME,xsd:dateTime) as ?founded_on_FIXDATETIME_xsd_dateTime)
      bind(replace(?last_funding_on,' ','T') as ?last_funding_on_FIXDATETIME)
      bind(strdt(?last_funding_on_FIXDATETIME,xsd:dateTime) as ?last_funding_on_FIXDATETIME_xsd_dateTime)
      bind(replace(?closed_on,' ','T') as ?closed_on_FIXDATETIME)
      bind(strdt(?closed_on_FIXDATETIME,xsd:dateTime) as ?closed_on_FIXDATETIME_xsd_dateTime)
      bind(if(?employee_count in ("other","not provided","unknown"),?UNDEF,?employee_count) as ?employee_count_IFNOTNULL)
      bind(lcase(replace(replace(replace(?employee_count_IFNOTNULL, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?employee_count_IFNOTNULL_URLIFY)
      bind(iri(concat("cb/employeeCount/",?employee_count_IFNOTNULL_URLIFY)) as ?cb_employeeCount_employee_count_IFNOTNULL_URLIFY_URL)
      bind(strdt(?facebook_url,xsd:anyURI) as ?facebook_url_xsd_anyURI)
      bind(strdt(?linkedin_url,xsd:anyURI) as ?linkedin_url_xsd_anyURI)
      bind(strdt(?twitter_url,xsd:anyURI) as ?twitter_url_xsd_anyURI)
      bind(strdt(?logo_url,xsd:anyURI) as ?logo_url_xsd_anyURI)
      bind(lcase(replace(replace(replace(?primary_role, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "")) as ?primary_role_URLIFY)
      bind(iri(concat("cb/organizationRole/",?primary_role_URLIFY)) as ?cb_organizationRole_primary_role_URLIFY_URL)
      bind(strdt(?num_exits,xsd:integer) as ?num_exits_xsd_integer)

   Generated Binds: Customers
    For the Customers example, the binds are pretty similar, but we use a
    slightly different definition of URLIFY (uses teh Unicode Numeric
    character class \p{N} instead of 0-9).

      bind(iri(concat("person/",?customer_id)) as ?person_URL)
      bind(iri(concat("person/",?customer_id,"/address")) as ?person_address_URL)
      bind(iri(concat("person/",?customer_id,"/birth")) as ?person_birth_URL)
      bind(iri(concat("person/",?customer_id,"/education")) as ?person_education_URL)
      bind(replace(replace(replace(?city,'[^\\p{L}\\p{N}]+','_'),'^_',''),'_$','') as ?city_URLIFY)
      bind(iri(concat("country/",?country,"/city/",?city_URLIFY)) as ?country_city_URLIFY_URL)
      bind(iri(concat("country/",?country)) as ?country_URL)
      bind(strdt(?date_of_birth,xsd:date) as ?date_of_birth_xsd_date)
      bind(strdt(?enrollment_date,xsd:date) as ?enrollment_DATE_xsd_date)
      bind(replace(replace(replace(?university,'[^\\p{L}\\p{N}]+','_'),'^_',''),'_$','') as ?university_URLIFY)
      bind(iri(concat("university/",university_URLIFY)) as ?university_URLIFY_URL)
      bind(replace(replace(replace(?education_degree,'[^\\p{L}\\p{N}]+','_'),'^_',''),'_$','') as ?education_degree_URLIFY)
      bind(iri(concat("degree/",?education_degree_URLIFY)) as ?education_degree_URLIFY

   Generated Update: Annual Revenue by Permalink
    This model adds some extra Revenue triples into a specified named graph.
    The overall OntoRefine UPDATE looks like this:

      delete where {graph <extra/revenue> {?x ?p ?o}};
      insert {graph  <extra/revenue> {
        ?permalink_CB_AGENT_URL ex:annualRevenueUsd ?revenue_xsd_decimal
      }}
      where {
        service <rdf-mapper:ontorefine:PROJECT_ID> {
          bind(?c_revenue as ?revenue)
          bind(strdt(?revenue,xsd:decimal) as ?revenue_xsd_decimal)
        }
        filter(bound(?permalink))
        ?permalink_CB_AGENT_URL a ?permalink_TYPE; k2:permalink ?permalink
        filter(?permalink_TYPE in (cb:Person,cb:Organization))
      };

    As you can see, the CB_AGENT_URL macro is evaluated outside of the
    OntoRefine virtual endpoint.

   Generated Binds: Spending Categories
      bind(iri(concat("grant/",?APPLICATION_ID)) as ?grant_APPLICATION_ID_URL)
      ?NIH_SPENDING_CATS_SPLIT apf:strSplit (?NIH_SPENDING_CATS "; ?").
      bind(replace(replace(replace(?NIH_SPENDING_CATS_SPLIT_SEMI, "[^\\p{L}0-9]", "_"), "_+", "_"), "^_|_$", "") as ?NIH_SPENDING_CATS_SPLIT_SEMI_URLIFY)
      bind(iri(concat("spendingCategory/",?NIH_SPENDING_CATS_SPLIT_SEMI_URLIFY)) as ?spendingCategory_NIH_SPENDING_CATS_SPLIT_SEMI_URLIFY_URL)

SEE ALSO
    The gist Crunchbase Semantic Model and Challenge
    <https://gist.github.com/VladimirAlexiev/d5d67feb002dbcfa6b3d4c3dd59b52d
    a> that publishes all our Crunchbase models. It also shows an overall
    model diagram made by rdfpuml.

    The issue Generate Transforms and Shapes from Models
    <https://github.com/kg-construct/best-practices/issues/7> in the
    Knowledge Graph Construct W3C community group "Best Practices" github
    project.

    rdfpuml: a tool that generates PlantUML diagrams from RDF examples.

    rdf2rml: a tool that generates R2RML transformations from RDF examples.

    rdf2tarql: a tool that generates TARQL queries from RDF examples.

AUTHOR
    Vladimir Alexiev, Ontotext Corp

    Last update: 15-Aug-2022

